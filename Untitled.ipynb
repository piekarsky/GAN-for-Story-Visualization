{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "import tensorflow.keras.layers as kl \n",
    "import tensorflow.keras.callbacks as kc \n",
    "import tensorflow.keras.backend as K \n",
    "import tensorflow.keras.optimizers as ko \n",
    "from tensorflow.keras.models import Model, load_model \n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join(os.getcwd(), 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path:str, limit:int=0):\n",
    "    \"Method that loads an image of the given path. The number of loaded images depends on the defined limit\"\n",
    "    \n",
    "    images = [] # initialization of the photo board\n",
    "    \n",
    "    for fname in tqdm(os.listdir(path)):\n",
    "        fpath = os.path.join(path, fname)\n",
    "        img = cv2.cvtColor(cv2.imread(fpath), cv2.COLOR_BGR2RGB) \n",
    "        if limit !=0 and limit == int(len(images)):\n",
    "            return images\n",
    "        images.append(img)\n",
    "        \n",
    "    return images\n",
    "\n",
    "def check_shape(images:list, shape=(160,160,3)):\n",
    "    'Method for verifying whether the images in the given list have the \"shape shape\" parameter'\n",
    "    counter = 0\n",
    "    for img in images:\n",
    "        if img.shape != shape:\n",
    "            print(\"Obrazy są różnego kształtu ;(!\")\n",
    "            counter +=1\n",
    "\n",
    "def plot_images(images:list,n:int):\n",
    "    \"Method for displaying data from the given list. Number of examples to be drawn - n * n\"\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(n**2):\n",
    "        plt.subplot(n,n,1+i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def change_size(images:list, size:tuple):\n",
    "    \n",
    "    \n",
    "    new_images = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(np.array(img), (size[1],size[0]), cv2.INTER_CUBIC)\n",
    "        new_images.append(img)\n",
    "    \n",
    "    return new_images\n",
    "\n",
    "def crop_imgs(images:list):\n",
    "    \n",
    "   \n",
    "    faces = []\n",
    "    cascade_path = os.path.join(os.getcwd(), 'haars/haarcascade_frontalface_alt.xml')\n",
    "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        face = face_cascade.detectMultiScale(gray, 1.3,5) #detekcja twarzy\n",
    "        \n",
    "        if len(face) == 1:\n",
    "            (x,y,w,h) = face[0] # koordynaty twarzy\n",
    "            roi_color = img[y:y+h, x:x+h] # wydzielenie obszaru z twarzą\n",
    "            faces.append(roi_color)\n",
    "    \n",
    "    print(\"Number of faces detected: \", len(faces))\n",
    "    return faces\n",
    "\n",
    "\n",
    "def normalize_imgs(images:np.array):\n",
    "    \"\"\"\n",
    "    Normalization of images to the interval <-1,1> - in order to use the hyperbolic tangent in the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    images = images.astype('float32')\n",
    "    images = (images - 127.5) / 127.5\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def build_generator(latent_dim:int):\n",
    "    \n",
    "      \n",
    "    x = kl.Dense(n_nodes)(inputs)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    x = kl.Reshape((5,5, 128))(x)\n",
    "    \n",
    "    \n",
    "    x = kl.Conv2DTranspose(128, filter_size, strides=(2,2), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = kl.Conv2DTranspose(128, filter_size, strides=(2,2), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    \n",
    "    x = kl.Conv2DTranspose(128, filter_size, strides=(2,2), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_size:tuple):\n",
    "    \n",
    "    \"\"\"\n",
    "    It defines a discriminator that takes images of a defined \"SHAPE\" shape as input and applies successive convolution layers to extract features and classify images.\n",
    "    For what creation we use the functional Keras API\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = kl.Input(shape=input_size)  # input layer\n",
    "    x = kl.Conv2D(128,(4,4), padding='same', input_shape=input_size)(inputs) # 64\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)  \n",
    "    \n",
    "    x = kl.Conv2D(128,(4,4), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = kl.Conv2D(128,(4,4), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = kl.Conv2D(128,(4,4), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = kl.Conv2D(128,(4,4), padding='same')(x)\n",
    "    x = kl.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = kl.Flatten()(x)\n",
    "    x = kl.Dropout(0.4)(x)\n",
    "    x = kl.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    discriminator = Model(inputs, x, name='discriminator')\n",
    "    return discriminator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (80,80,3) \n",
    "\n",
    "imgs = read_images(dataset_path,3500) \n",
    "faces = crop_imgs(imgs) \n",
    "del imgs \n",
    "\n",
    "faces = change_size(faces,size=SHAPE) \n",
    "check_shape(faces, SHAPE)\n",
    "plot_images(faces,12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = build_discriminator(input_size=SHAPE) \n",
    "plot_model(D,'./discriminator.png')\n",
    "D.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "epochs = 50000 \n",
    "sample_period = 200 \n",
    "learning_rate_D = 0.0002 \n",
    "learning_rate_G = 0.0002 \n",
    "\n",
    "ones =  np.ones(batch_size) \n",
    "zeros = np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    noisy_ones = noisy_labels(ones,0,0.2).astype('float32').reshape(-1,1) \n",
    "    noisy_zeros = noisy_labels(zeros,1,0.2).astype('float32').reshape(-1,1) \n",
    "    idx = np.random.randint(0, faces.shape[0], batch_size) \n",
    "    real_imgs = faces[idx]\n",
    "     \n",
    "    noise = np.random.randn(batch_size, latent_dim) \n",
    "    fake_imgs = G.predict(noise) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
